{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, n_features):\n",
    "    encoding = list()\n",
    "    for value in sequence:\n",
    "        vector = [0 for _ in range(n_features)]\n",
    "        vector[value - 1] = 1\n",
    "        encoding.append(vector)\n",
    "    return numpy.array(encoding)\n",
    "\n",
    "\n",
    "def one_hot_decode(code):\n",
    "    return [(numpy.argmax(vector) + 1) for vector in code]\n",
    "\n",
    "\n",
    "def create_dataset(data, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(data.shape[0] - look_back - 1):\n",
    "        dataX.append(data[i:(i + look_back), :])\n",
    "        dataY.append(data[i + look_back, :])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = read_csv(\"../data/special.csv\", header=None)\n",
    "# dataframe = read_csv(\"../data/fake.csv\", header=None)\n",
    "dataset = dataframe.values[:, 0]\n",
    "print dataset.shape\n",
    "\n",
    "n_features = 49\n",
    "code = one_hot_encode(dataset, n_features)\n",
    "\n",
    "train_size = 100\n",
    "test_size = 51\n",
    "train, test = code[0:train_size, :], code[train_size:len(code), :]\n",
    "print(code.shape, train.shape, test.shape)\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 8\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "print trainX.shape, trainY.shape\n",
    "print one_hot_decode(trainX[0, :, :]), one_hot_decode([trainY[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 32\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_size, input_shape=(\n",
    "    look_back, n_features), return_sequences=True))\n",
    "model.add(LSTM(hidden_size, input_shape=(look_back, n_features)))\n",
    "model.add(Dense(n_features, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "# fit model\n",
    "model.fit(trainX, trainY, epochs=1000, batch_size=8, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  evaluate model with training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(trainX, trainY)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "trainYhat = model.predict(trainX)\n",
    "for i in range(trainX.shape[0]):\n",
    "    print [one_hot_decode(trainX[i, :, :]), one_hot_decode(\n",
    "        [trainY[i]]), one_hot_decode([trainYhat[i]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  evaluate model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(testX, testY)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "testYhat = model.predict(testX)\n",
    "for i in range(testX.shape[0]):\n",
    "    print [one_hot_decode(testX[i, :, :]), one_hot_decode(\n",
    "        [testY[i]]), one_hot_decode([testYhat[i]])]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
